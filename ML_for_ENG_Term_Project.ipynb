{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for ENG: Term Project Phase II\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Authors:}$ Soo Min Kwon, Manish Kewalramani, Brian Cheng\n",
    "\n",
    "<br>\n",
    "\n",
    "# Image Dataset: Clustering\n",
    "\n",
    "<br>\n",
    "This part of the Jupyter Notebook is for the $\\textbf{CIFAR-10 Dataset}$ for the task of $\\textbf{clustering}$.\n",
    "\n",
    "Each section of this notebook will have code accompanied by a $\\textit{remark}$ section for reasoning of why and what is done in the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing as sklpp\n",
    "from sklearn import decomposition as skldecomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will be loading and reshaping the $\\textbf{CIFAR-10}$ dataset into the format that we need for clustering.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Pre-processing and Loading of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Names: [b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n",
      "Shape of Training Data: (50000, 32, 32, 3)\n",
      "Shape of Training Data Labels: (50000, 1)\n",
      "Shape of Testing Data: (10000, 32, 32, 3)\n",
      "Shape of Testing Data Labels: (10000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data\n",
    "\n",
    "file_path = 'CIFAR-10 Data'\n",
    "\n",
    "num_files = 5\n",
    "num_samples = 10000\n",
    "num_image_data = 3072\n",
    "image_dim = 32\n",
    "\n",
    "training_data = np.zeros((num_samples*5, num_image_data))\n",
    "training_labels = np.zeros((num_samples*5, 1))\n",
    "training_label_names = []\n",
    "testing_data = np.zeros((num_samples, num_image_data))\n",
    "testing_labels = np.zeros((num_samples, 1))\n",
    "\n",
    "st = 0\n",
    "en = num_samples\n",
    "\n",
    "for num in range(num_files):\n",
    "    # for label names\n",
    "    labels_dictionary = unpickle(file_path + '/batches.meta')\n",
    "    training_label_names = labels_dictionary[b'label_names']\n",
    "    \n",
    "    # for training data\n",
    "    training_data_dictionary = unpickle(file_path + '/data_batch_' + str(num))\n",
    "    train_data_dict = training_data_dictionary[b'data']\n",
    "    train_labels_dict = training_data_dictionary[b'labels']\n",
    "    \n",
    "    train_labels_dict = np.reshape(train_labels_dict, (num_samples, 1))\n",
    "    training_data[st:en, :] = train_data_dict\n",
    "    training_labels[st:en, :] = train_labels_dict\n",
    "    \n",
    "    # for testing data\n",
    "    testing_data_dictionary = unpickle(file_path + '/test_batch')\n",
    "    test_data_dict = testing_data_dictionary[b'data']\n",
    "    test_labels_dict = testing_data_dictionary[b'labels']\n",
    "    \n",
    "    test_labels_dict = np.reshape(test_labels_dict, (num_samples, 1))\n",
    "    testing_data = test_data_dict\n",
    "    testing_labels = test_labels_dict\n",
    "    \n",
    "    st += num_samples\n",
    "    en += num_samples\n",
    "\n",
    "# reshaping data into images\n",
    "cifar_train_data = np.reshape(training_data, (num_samples*5, 3, image_dim, image_dim))\n",
    "cifar_train_data = cifar_train_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "\n",
    "cifar_test_data = np.reshape(testing_data, (num_samples, 3, image_dim, image_dim))\n",
    "cifar_test_data = cifar_test_data.transpose(0, 2, 3, 1).astype(np.float32)\n",
    "\n",
    "# printing one training and one testing image and showing shapes of data\n",
    "one_train_image = cifar_train_data[5, :, :, :]\n",
    "one_test_image = cifar_test_data[5, :, :, :]\n",
    "\n",
    "plt.imshow(one_train_image.astype('uint8'))\n",
    "plt.title('First Training Image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(one_test_image.astype('uint8'))\n",
    "plt.title('First Testing Image')\n",
    "plt.show()\n",
    "\n",
    "# printing shapes\n",
    "print('Label Names: ' + str(training_label_names))\n",
    "print('Shape of Training Data: ' + str(cifar_train_data.shape))\n",
    "print('Shape of Training Data Labels: ' + str(training_labels.shape))\n",
    "print('Shape of Testing Data: ' + str(cifar_test_data.shape))\n",
    "print('Shape of Testing Data Labels: ' + str(testing_labels.shape) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks:}$\n",
    "\n",
    "The CIFAR-10 dataset can be downloaded with the following link: http://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "After downloading the file with the link provided, the file containing the data has 7 \"pickle\" files. Each pickle file contains a Python Dictionary of elements needed for a ML algorithm. Though clustering is an unsupervised learning method, we can still utilize the labels to observe how well our clustering was performed. For each of the files in the data file:\n",
    "\n",
    "The pickle file labeled \"batches.meta\" has the names of labels for each image. There are 10 different classes of images, so the shape of the array of labels should be 10. The names of labels are printed above. For example, a label of 0 would indicate the class of 'airplane'.\n",
    "\n",
    "The pickle files labeled \"data_batch_0, ..., data_batch_4\" are the files for the training data. We reshape the data into a 4th order tensor with the following axis:\n",
    "(samples, image_dimensions, image_dimensions, RGB 3 channels).\n",
    "\n",
    "The pickle file labeled \"test_batch\" is the file for testing data. We reshape the data into a 4th order tensor with the following axis:\n",
    "(samples, image_dimensions, image_dimensions, RGB 3 channels).\n",
    "\n",
    "$\\textit{Note: }$Since these images are small (32x32), they are not clear when shown.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Learning / Feature Extraction for K-Means\n",
    "\n",
    "Each of our group members will do a different feature extraction method for K-means clustering. The three feature extraction methods that we will be exploring is $\\textbf{Principal Component Analysis (PCA)}$, $\\textbf{Scale-Invariant Feature Tranform (SIFT)}$ (on grayscale images), and $\\textbf{SIFT}$ (on RGB images) with $\\textbf{PCA}$. We decided to do three different feature extraction methods because we realized that doing K-means with Euclidean distance for image clustering was giving unsatisfactory results, and simply changing the distance metrics would have NOT made performance any better. The following blocks of codes is split by author, and labeled by each feature extraction methods used.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering with PCA\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author: }$ Soo Min Kwon\n",
    "\n",
    "<br>\n",
    "\n",
    "For this feature learning section, we will perform Principal Component Analysis (PCA) to reduce the dimensions of our data. To first perform PCA, we must center our data. Upon centering our data, we verify that it's centered and use the Scikit-Learn package. But before doing PCA, we will make our images grayscale. This is because working with RGB images may get complicated, and must by reshaped perfectly for decent results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Dimensions: (50000, 1024)\n",
      "Verification of Centered Mean: [-6.7456053e-06 -1.3824463e-07 -4.5764159e-06 ...  1.8692016e-07\n",
      " -9.5970154e-06 -8.7265016e-06]\n"
     ]
    }
   ],
   "source": [
    "# mean centering for PCA\n",
    "cifar_gray_train_data = rgb2gray(cifar_train_data)\n",
    "cifar_gray_train_data = np.reshape(cifar_gray_train_data, (num_samples*5, image_dim*image_dim))\n",
    "\n",
    "mean_scaler = sklpp.StandardScaler(with_mean=True, with_std=False)\n",
    "centered_train_data = mean_scaler.fit_transform(cifar_gray_train_data)\n",
    "\n",
    "# verifying if mean was centered correctly\n",
    "means = np.mean(centered_train_data, axis=0)\n",
    "\n",
    "# verifying reshaped dimensions and centered mean\n",
    "print('Reshaped Dimensions: ' + str(centered_train_data.shape))\n",
    "print('Verification of Centered Mean: ' + str(means))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the block of code above, we centered our data for PCA. We were able to verify that the mean was centered correctly using Scikit Learn by printing the means of the centered data.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCA Features with 95% Energy Capture: 160\n"
     ]
    }
   ],
   "source": [
    "# performing PCA with 95% energy capture\n",
    "do_PCA = skldecomp.PCA(n_components=0.95, svd_solver='full')\n",
    "cifar_features = do_PCA.fit_transform(centered_train_data)\n",
    "num_pca_features = do_PCA.components_.shape[0]\n",
    "\n",
    "print('Number of PCA Features with 95% Energy Capture: ' + str(num_pca_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "For the number of principal components to use for PCA, we ran our codes a couple times with different energy captures to see which would be best fit. Amongst our observations, we thought that it would be best suitable to use an energy capture of 95%, as it reduces dimensions significantly and can reconstruct the images upon projection quite well.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# projecting the features\n",
    "cifar_projected_images = do_PCA.inverse_transform(cifar_features)\n",
    "cifar_projected_images = np.reshape(cifar_projected_images, (num_samples*5, image_dim, image_dim))\n",
    "plt.imshow(cifar_projected_images[5, :, :], cmap='gray')\n",
    "plt.title('PCA Projected Image')\n",
    "plt.show()\n",
    "\n",
    "gray_image = np.reshape(cifar_gray_train_data, (50000, 32, 32))\n",
    "plt.imshow(gray_image[5, :, :], cmap='gray')\n",
    "plt.title('Original Grayscale Image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(cifar_projected_images[10, :, :], cmap='gray')\n",
    "plt.title('PCA Projected Image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(gray_image[10, :, :], cmap='gray')\n",
    "plt.title('Original Grayscale Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks:}$\n",
    "\n",
    "The first two images are images of a car. The first image is the projected images after using PCA with an energy capture of 95%. The image following that is the original car image before any processing. The same goes for the next two images, which is a picture of a deer.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels from K-Means Using PCA: [9 6 8 ... 8 1 4]\n",
      "Computation Time for K-Means with PCA: 18.391259908676147 seconds\n"
     ]
    }
   ],
   "source": [
    "# performing K-means clustering with 10 clusters\n",
    "start_time_PCA = time.time()\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(cifar_features)\n",
    "\n",
    "end_time_PCA = time.time()\n",
    "\n",
    "elapsed_time_PCA = end_time_PCA - start_time_PCA\n",
    "\n",
    "print('Labels from K-Means Using PCA: ' + str(kmeans.labels_))\n",
    "print('Computation Time for K-Means with PCA: ' + str(elapsed_time_PCA) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Data to be Clustered: (50000, 160)\n",
      "Dimensions of Labels from K-Means: (50000,)\n",
      "Dimensions of True Labels: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# printing shapes of data for verification\n",
    "print('Dimensions of Data to be Clustered: ' + str(cifar_features.shape))\n",
    "print('Dimensions of Labels from K-Means: ' + str(kmeans.labels_.shape))\n",
    "print('Dimensions of True Labels: ' + str(training_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "In the blocks of code above, we verified the dimensions of all of our variables to double check that everything came out correctly. The data that we used for clustering was the one we processed using PCA, with the columns being the number of principal components used.\n",
    "\n",
    "The K-Means algorithm implemented on Scikit-Learn was the one we learned in class, which was the $\\textit{Lloyd's algorithm for Quantization}$. The algorithm initializes 10 clusters randomly, computes the centroid of each cluster, keeps cluster with the smallest Euclidean distance value, and loops until no more changes occur.\n",
    "\n",
    "As for the code, the \"n_clusters\" argument defines the number of clusters to be used. Since we have 10 different classes of images, we use 10 clusters. The \"fit\" followed by the input computes K-means clustering given the data to be clustered. The \"random_state\" determines random number generation for centroid initialization. It is often unnecessary for an input for this arugment. The distance metric that Scikit-Learn uses by default for K-means is the Euclidean distance.\n",
    "\n",
    "For more information: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels:     [[6 9 9 4 1 1 2 7 8 3 4 7 7 2 9 9 9 3 2 6 4 3 6 6 2 6 3 5 4 0 0 9 1 3 4]]\n",
      "Predicted Labels: [9 6 8 3 2 2 6 0 7 2 3 4 4 3 2 1 1 9 4 0 5 3 3 2 2 4 2 3 4 1 6 8 2 9 4]\n"
     ]
    }
   ],
   "source": [
    "# for visualization of true and predicted labels\n",
    "print('True Labels:     ' + str((training_labels[0:35].T).astype(int)))\n",
    "print('Predicted Labels: ' + str(np.asarray(kmeans.labels_[0:35])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Just to visualize how well K-means clustering performed, we observe and compare the first 35 true and predicted labels. Obviously, the labels shouldn't exactly match. Scikit-Learn does not know how the true labels are indexed. However, if there are patterns in the true labels (e.g. 1, 1, 2, 2) then there should be the same patterns but with different (or same) numbers in the same indices (e.g. 3, 3, 4, 4). For example, in the print statement above, if we look at 5th and 6th indices for both true and predicted labels, we can observe this pattern. \n",
    "\n",
    "$\\textbf{Note:}$ This is just for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with PCA as Features: \n",
      "[[ 240.  387.  410.  698. 1068.  709.  459.  891.  188.  188.]\n",
      " [ 695.  480.  200.  156.  201.  107.   79.  236. 1324.  670.]\n",
      " [ 400.  997.  750.  629.  782.  519.  922.  605.  378.  773.]\n",
      " [ 214.  457.  511.  626.  488.  457.  829.  265.  168.  148.]\n",
      " [ 433.  478.  427.  465.  353.  411.  472.  999.  207.  721.]\n",
      " [ 955.  257.  430.  299.  143.  182.  260.  169.  213.  199.]\n",
      " [ 699.  620.  996.  609.  855.  792.  815.  605.  938.  567.]\n",
      " [ 743.  117.  801.  548.  609.  704.  327.  455.  317.   95.]\n",
      " [ 392.  678.  182.  250.  195.  144.  125.  422.  798. 1488.]\n",
      " [ 229.  529.  293.  720.  306.  975.  712.  353.  469.  151.]]\n"
     ]
    }
   ],
   "source": [
    "# hand-made confusion matrix\n",
    "confusionmatrix = np.zeros((10,10))\n",
    "\n",
    "st = 0\n",
    "en = 1\n",
    "\n",
    "for k in range(50000):\n",
    "    x = int(kmeans.labels_[st:en])\n",
    "    y = int(training_labels[st:en])\n",
    "    confusionmatrix[x][y] += 1\n",
    "    st+=1\n",
    "    en+=1\n",
    "print('Confusion Matrix with PCA as Features: ' + '\\n' + str(confusionmatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Since the label numbers from K-means and the true labels don't directly match, we created a hand-made confusion matrix with the rows being the predicted classes and the columns being the true classes. The way that we created this confusion matrix is that we iterated through both arrays of labels and incremented the confusion matrix in that specific position given the number of labels.\n",
    "\n",
    "$\\textbf{Example:}$\n",
    "\n",
    "Let's say that the predicted class for the first index for K-means labels was 2, and for that same index, the true label was 7. Then, the [7][2] index of the confusion matrix would be incremented by 1. Ideally, we should see a very high number in one element of a column of the confusion matrix, and the rest low numbers in the elements of the same column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering with SIFT\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author: }$ Brian Cheng\n",
    "\n",
    "<br>\n",
    "\n",
    "K-Means clustering using the PCA features did not get the results we wanted, and upon reaching out for advice, we decided to take a new approach for our feature learning method, which was to use the vectors from SIFT as features. Scale-Invariant Feature Tranform (SIFT) has 4 steps in its algorithm:\n",
    "\n",
    "1. Scale-Space Extrema Detection\n",
    "\n",
    "We first detect keypoint extremas by running Gaussian and Laplacian filters over the images. This can be computationally intensive because to find larger keypoints in portions of the image, we need larger filter sizes. So instead of using LoG (Laplacian of Gaussian), we use Difference of Gaussian, which is an approximation of LoG.\n",
    "\n",
    "2. Keypoint Localization\n",
    "\n",
    "Once potential keypoints are found, they have to be refined for more accurate results. We use the Taylor series expansion of scale space to get more accurate location of the keypoints, and if the intensity at this extrema is less than a threshold value, it is rejected.\n",
    "\n",
    "3. Orientation Assignment\n",
    "\n",
    "An orientation is assigned to each keypoint to achieve invariance to image rotation.\n",
    "\n",
    "4. Keypoint Descriptor\n",
    "\n",
    "Once the keypoints are oriented, a neighborhood around the keypoints are made.\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "For more details about SIFT on OpenCV: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implmenting SIFT\n",
    "cifar_gray_train_data = np.reshape(cifar_gray_train_data, (num_samples*5, image_dim, image_dim))\n",
    "\n",
    "total_images = num_samples*5\n",
    "target_keypoints = 39\n",
    "dim_vec = 128\n",
    "\n",
    "cifar_sift_features = np.zeros((total_images, target_keypoints, dim_vec))\n",
    "\n",
    "for num in range(total_images):\n",
    "    per_image = cifar_gray_train_data[num, :, :]\n",
    "    gray_image = cv2.normalize(per_image, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    \n",
    "    cifar_sift_features[num, :len(keypoints), :] = cifar_sift_features[num, :len(keypoints), :] + descriptors \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "To use SIFT, we used a package implemented on OpenCV. The number of target_keypoints is 39 because that was the maximum number of keypoints given from all the images. If the image had less than 39 keypoints, we zero-padded to match 39 keypoints. Each keypoint had a 128-dimensional vector, so the whole feature matrix for each image had dimensions (39 x 128). We then vectorize these dimensions to fit it into the K-means clustering algorithm using Scikit Learn.\n",
    "\n",
    "For more information on SIFT: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_sift_intro/py_sift_intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Vectorized Features: (50000, 4992)\n"
     ]
    }
   ],
   "source": [
    "cifar_sift_features = np.reshape(cifar_sift_features, (total_images, target_keypoints*dim_vec))\n",
    "print('Dimensions of Vectorized Features: ' + str(cifar_sift_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels from K-Means Using SIFT: [4 1 2 ... 5 6 7]\n",
      "Computation Time for K-Means with SIFT: 385.67128801345825 seconds\n"
     ]
    }
   ],
   "source": [
    "# using K-means onto new features\n",
    "start_time_sift = time.time()\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(cifar_sift_features)\n",
    "\n",
    "end_time_sift = time.time()\n",
    "\n",
    "elapsed_time_sift = end_time_sift - start_time_sift\n",
    "\n",
    "print('Labels from K-Means Using SIFT: ' + str(kmeans.labels_))\n",
    "print('Computation Time for K-Means with SIFT: ' + str(elapsed_time_sift) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels:     [[6 9 9 4 1 1 2 7 8 3 4 7 7 2 9 9 9 3 2 6 4 3 6 6 2 6 3 5 4 0 0 9 1 3 4]]\n",
      "Predicted Labels: [4 1 2 8 8 7 1 2 4 9 2 0 5 8 0 7 2 4 2 0 2 9 6 0 4 0 9 8 7 2 3 5 9 1 9]\n"
     ]
    }
   ],
   "source": [
    "print('True Labels:     ' + str((training_labels[0:35].T).astype(int)))\n",
    "print('Predicted Labels: ' + str(np.asarray(kmeans.labels_[0:35])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with SIFT as Features: \n",
      "[[ 337.  539.  348.  470.  493.  424.  489.  763.  177.  789.]\n",
      " [ 124.  352.  172.  296.  312.  515.  343.  567.   82.  517.]\n",
      " [ 662.  612.  674.  516.  552.  366.  514.  532.  526.  713.]\n",
      " [1465.  235.  916.  308.  332.  194.  302.  147. 1395.  158.]\n",
      " [ 192.  504.  339.  591.  460.  721.  574.  449.  242.  315.]\n",
      " [ 218.  615.  317.  550.  586.  657.  544.  751.  165.  762.]\n",
      " [ 338.  417.  485.  549.  573.  575.  583.  371.  620.  274.]\n",
      " [1052.  570.  947.  605.  674.  454.  577.  434. 1114.  485.]\n",
      " [ 239.  515.  404.  663.  504.  698.  644.  386.  399.  274.]\n",
      " [ 373.  641.  398.  452.  514.  396.  430.  600.  280.  713.]]\n"
     ]
    }
   ],
   "source": [
    "# hand-made confusion matrix\n",
    "confusionmatrix = np.zeros((10,10))\n",
    "\n",
    "st = 0\n",
    "en = 1\n",
    "\n",
    "for k in range(50000):\n",
    "    x = int(kmeans.labels_[st:en])\n",
    "    y = int(training_labels[st:en])\n",
    "    confusionmatrix[x][y] += 1\n",
    "    st+=1\n",
    "    en+=1\n",
    "    \n",
    "print('Confusion Matrix with SIFT as Features: ' + '\\n' + str(confusionmatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Performing SIFT and using the resulting features for K-means clustering did not work very well. The way that we evaluated the K-means clustering algorithm was the same method that we did for PCA, which was to make a confusion matrix for the predicted and true class labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering with SIFT and PCA\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author: }$ Manish Kewalramani\n",
    "\n",
    "<br>\n",
    "\n",
    "Since both methods (PCA and SIFT) for feature learning did not work very well, our third thought was to compare the computational complexity of SIFT vs. SIFT & PCA. Since the number of features for SIFT was quite large, the K-means clustering algorithm took a long time to finish. If we can get similar results for doing SIFT & PCA and just SIFT, we can conclude that it is better to do SIFT & PCA together, as it significantly reduces computational complexity and outputs similar results. Generally, however, since SIFT did not give satisfactory results, we shouldn't expect good results for SIFT & PCA.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implmenting SIFT\n",
    "total_images = num_samples*5\n",
    "target_keypoints = 39\n",
    "dim_vec = 128\n",
    "\n",
    "cifar_sift_features = np.zeros((total_images, target_keypoints, dim_vec))\n",
    "\n",
    "for num in range(total_images):\n",
    "    per_image = cifar_train_data[num, :, :]\n",
    "    image = cv2.normalize(per_image, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    \n",
    "    cifar_sift_features[num, :len(keypoints), :] = cifar_sift_features[num, :len(keypoints), :] + descriptors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of SIFT Features: (50000, 39, 128)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of SIFT Features: ' + str(cifar_sift_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "SIFT was performed the same way (using OpenCV) as previously done.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Dimensions: (50000, 4992)\n",
      "Verification of Centered Mean: [-4.38627978e-14  2.83759505e-14  2.20421725e-14 ...  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# PCA on SIFT features\n",
    "cifar_sift_features = np.reshape(cifar_sift_features, (total_images, target_keypoints*dim_vec))\n",
    "mean_scaler = sklpp.StandardScaler(with_mean=True, with_std=False)\n",
    "centered_sift = mean_scaler.fit_transform(cifar_sift_features)\n",
    "\n",
    "# verifying if mean was centered correctly\n",
    "means = np.mean(centered_sift, axis=0)\n",
    "\n",
    "# verifying reshaped dimensions and centered mean\n",
    "print('Reshaped Dimensions: ' + str(centered_sift.shape))\n",
    "print('Verification of Centered Mean: ' + str(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCA Features with 95% Energy Capture: 1457\n"
     ]
    }
   ],
   "source": [
    "# performing PCA with 95% energy capture\n",
    "do_PCA = skldecomp.PCA(n_components=0.95, svd_solver='full')\n",
    "cifar_features = do_PCA.fit_transform(centered_sift)\n",
    "num_pca_features = do_PCA.components_.shape[0]\n",
    "\n",
    "print('Number of PCA Features with 95% Energy Capture: ' + str(num_pca_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions before PCA:(50000, 4992)\n",
      "Dimensions after PCA: (50000, 1457)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions before PCA:' + str(centered_sift.shape))\n",
    "print('Dimensions after PCA: ' + str(cifar_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "PCA was performed the same way (using Scikit-Learn) as previously done.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels from K-Means Using SIFT & PCA: [6 0 9 ... 0 2 8]\n",
      "Computation Time for K-Means with SIFT & PCA: 114.14728689193726 seconds\n"
     ]
    }
   ],
   "source": [
    "# performing K-means\n",
    "start_time_sift_PCA = time.time()\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(cifar_features)\n",
    "\n",
    "end_time_sift_PCA = time.time()\n",
    "\n",
    "elapsed_time_sift_PCA = end_time_sift_PCA - start_time_sift_PCA\n",
    "\n",
    "print('Labels from K-Means Using SIFT & PCA: ' + str(kmeans.labels_))\n",
    "print('Computation Time for K-Means with SIFT & PCA: ' + str(elapsed_time_sift_PCA) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "K-means was performed the same way (using Scikit-Learn) as previously done.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels:     [[6 9 9 4 1 1 2 7 8 3 4 7 7 2 9 9 9 3 2 6 4 3 6 6 2 6 3 5 4 0 0 9 1 3 4]]\n",
      "Predicted Labels: [6 0 9 2 2 4 0 4 0 3 6 0 0 6 9 8 5 6 9 2 9 4 1 6 6 5 5 2 8 9 1 7 9 7 5]\n"
     ]
    }
   ],
   "source": [
    "print('True Labels:     ' + str((training_labels[0:35].T).astype(int)))\n",
    "print('Predicted Labels: ' + str(np.asarray(kmeans.labels_[0:35])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with SIFT as Features: \n",
      "[[ 278.  662.  322.  563.  503.  627.  551.  837.  193.  828.]\n",
      " [1198.  140.  754.  211.  343.  124.  251.   89. 1092.   99.]\n",
      " [ 248.  456.  424.  583.  544.  604.  611.  378.  446.  246.]\n",
      " [ 213.  580.  380.  603.  515.  649.  566.  460.  305.  403.]\n",
      " [ 665.  615.  717.  599.  662.  456.  623.  498.  718.  526.]\n",
      " [ 394.  524.  331.  423.  403.  350.  410.  648.  242.  806.]\n",
      " [ 138.  510.  316.  544.  437.  689.  520.  429.  216.  331.]\n",
      " [ 152.  465.  222.  413.  356.  658.  392.  638.   96.  634.]\n",
      " [1117.  462. 1017.  576.  722.  475.  629.  389. 1273.  373.]\n",
      " [ 597.  586.  517.  485.  515.  368.  447.  634.  419.  754.]]\n"
     ]
    }
   ],
   "source": [
    "# hand-made confusion matrix\n",
    "confusionmatrix = np.zeros((10,10))\n",
    "\n",
    "st = 0\n",
    "en = 1\n",
    "\n",
    "for k in range(50000):\n",
    "    x = int(kmeans.labels_[st:en])\n",
    "    y = int(training_labels[st:en])\n",
    "    confusionmatrix[x][y] += 1\n",
    "    st+=1\n",
    "    en+=1\n",
    "    \n",
    "print('Confusion Matrix with SIFT as Features: ' + '\\n' + str(confusionmatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Evaluation of K-means was performed the same way (using hand-made confusion matrix) as previously done.\n",
    "\n",
    "Since we still get unsatisfactory results, but the computation time was much faster, we can conclude that it is better to do SIFT & PCA than just SIFT.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Final Remarks: }$\n",
    "\n",
    "Performing PCA, SIFT, and SIFT & PCA were not satisfactory for image clustering. Some future works can circle around exploring different feature learning methods on different images. We tried to do SURF and ORB on our dataset, but the image resolution was too poor to perform these feature methods.\n",
    "\n",
    "Computation Time for K-Means with PCA: 18.3913 seconds\n",
    "\n",
    "Computation Time for K-Means with SIFT: 385.671 seconds\n",
    "\n",
    "Computation Time for K-Means with SIFT & PCA: 114.147 seconds\n",
    "\n",
    "<br>\n",
    "\n",
    "Above are the computation times for the K-means clustering algorithm without overhead. \n",
    "\n",
    "For production, our recommendation would be to NOT do clustering with images. However, if we had to choose a feature learning method for clustering with images, we would say to do PCA, as it takes the least computation time and achieves similar (bad) results. \n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Dataset: Classification\n",
    "\n",
    "<br>\n",
    "This part of the Jupyter Notebook is for the $\\textbf{Google Audioset Dataset}$ for the task of $\\textbf{classification}$.\n",
    "\n",
    "The machine learning objective is binary classification of either human speech or other sound (not human speech).\n",
    "\n",
    "Each section of this notebook will have code accompanied by a $\\textit{remark}$ section for reasoning of why and what is done in the codes.\n",
    "\n",
    "<br>\n",
    "\n",
    "Below, we will be loading and reshaping the $\\textbf{Google Audioset}$ dataset into the format that we need for classification.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Pre-processing and Loading of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "hdf5_path = 'bal_train.h5'\n",
    "\n",
    "def load_data(hdf5_path):\n",
    "    with h5py.File(hdf5_path, 'r') as hf:\n",
    "        x = hf.get('x')\n",
    "        y = hf.get('y')\n",
    "        video_id_list = hf.get('video_id_list')\n",
    "        x = np.array(x)\n",
    "        y = list(y)\n",
    "        video_id_list = list(video_id_list)\n",
    "        \n",
    "    return x, y, video_id_list\n",
    "\n",
    "def uint8_to_float32(x):\n",
    "    return (np.float32(x) - 128.) / 128.\n",
    "    \n",
    "def bool_to_float32(y):\n",
    "    return np.float32(y)\n",
    "\n",
    "(x, y, video_id_list) = load_data(hdf5_path)\n",
    "x = uint8_to_float32(x)\n",
    "y = bool_to_float32(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "The above cell was used to load the training data of feature vectors into workable numpy arrays. The dataset is audio samples from 10 second youtube clips with 128 dimensional feature vectors sampled at 1 Hz. The data was downloaded preprocessed from the Google Audioset Website. The preprocessing steps that they took were the following:\n",
    "\n",
    "- Instead of raw audio, every example is made available as a sequence of 128-dimension embeddings (one embedding for every second of audio). The embeddings were obtained after passing the log-scaled mel-spectrograms of the audio waveform through a deep convolutional neural network trained on millions of audio clips (VGGish). \n",
    "\n",
    "Link for VGGish: https://resources.wolframcloud.com/NeuralNetRepository/resources/VGGish-Feature-Extractor-Trained-on-YouTube-Data\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Data: (22160, 10, 128)\n",
      "Dimensions of Labels: (22160, 527)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of Data: ' + str(x.shape))\n",
    "print('Dimensions of Labels: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Since the each audio clip was 10 seconds long in total and our 128 dimensional feature vectors were extracted from samples taken at 1 Hz, the dimensions of our data is 22160 (total number of samples) $\\times$ 10 (total number of seconds in an audio clip) $\\times$ 1 Hz (sampling rate) $\\times$ 128 (feature vector size). \n",
    "\n",
    "The labels were originally \"one-hot\" encoded, so the dimensions of each label are 527, for the number of different classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of New Labels for Each Audio Clip: (22160,)\n",
      "Total of Human Speech in Dataset: 5735\n",
      "New Labels: [0. 1. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# changing one-hot encoding\n",
    "newlabels = np.zeros((22160))\n",
    "counter = 0\n",
    "for i in range(y.shape[0]):\n",
    "    if y[i][0] == 1:\n",
    "        newlabels[i] = 1\n",
    "        counter += 1\n",
    "    \n",
    "# label of 1 indicates human speech, label of 0 indicates not human speech\n",
    "print('Shape of New Labels for Each Audio Clip: ' + str(newlabels.shape))\n",
    "print('Total of Human Speech in Dataset: ' + str(counter))\n",
    "print('New Labels: ' + str(newlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "In the cell above, we changed all the \"one-hot\" encoded labels into labels of 0 or 1. A label of 1 means that the audio clip is human speech and a label of 0 means not human speech. We can verify that the labels were correctly translated, as the new labels are now either 0 or 1 in the print statement above.\n",
    "\n",
    "From the whole dataset, there is a total of 5735 audio clips that are labeled as human speech. We were able to determine this number from a .csv file that had all the audio clips labeled.\n",
    "\n",
    "Below, we reshape our data into vectors to fit into our classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Reshaped Data: (22160, 1280)\n"
     ]
    }
   ],
   "source": [
    "# reshaping into vectors\n",
    "sample_size = x.shape[0]\n",
    "seconds = 10\n",
    "samp_freq = 128\n",
    "xvectors = np.reshape(x, (sample_size, seconds*samp_freq))\n",
    "print('Dimensions of Reshaped Data: ' + str(xvectors.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing SVM with a different dataset\n",
    "hdf5_path = 'eval.h5'\n",
    "\n",
    "(xtest, ytest, video_id_list) = load_data(hdf5_path)\n",
    "xtest = uint8_to_float32(xtest)\n",
    "ytest = bool_to_float32(ytest)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Test Data: (20371, 10, 128)\n",
      "Dimensions of Test Labels: (20371, 527)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions of Test Data: ' + str(xtest.shape))\n",
    "print('Dimensions of Test Labels: ' + str(ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of New Labels: (20371,)\n",
      "Total of Human Speech in Dataset: 5324\n"
     ]
    }
   ],
   "source": [
    "# changing labels and counting number of human speech data\n",
    "sample_size = xtest.shape[0]\n",
    "newlabelsTest = np.zeros((sample_size))\n",
    "countertest = 0\n",
    "for i in range(ytest.shape[0]):\n",
    "    if ytest[i][0] == 1:\n",
    "        newlabelsTest[i] = 1\n",
    "        countertest += 1\n",
    "    \n",
    "#label of 1 indicates human speech, label of 0 indicates not human speech\n",
    "print('Dimensions of New Labels: ' + str(newlabelsTest.shape))\n",
    "print('Total of Human Speech in Dataset: ' + str(countertest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing data for predictions\n",
    "xvectorstest = np.reshape(xtest,(sample_size, seconds*samp_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "To test our SVM model, we loaded another dataset 'eval.h5' and tested the accuracy, precision, recall, and F1-score. The pre-processing of this new dataset was the same as what we did for training, where we take the one-hot encoded labels and convert them into binary labels of 0 and 1. We vectorize these below and test the accuracy of our SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Support Vector Machines (SVM)\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author: }$ Manish Kewalramani\n",
    "\n",
    "<br>\n",
    "\n",
    "For the first binary classification task, we will implement SVM with Scikit-Learn.\n",
    "\n",
    "As we know, SVM tries to find a hyperplane using a hinge loss function. We assume our data is not completely separable, so we use soft-margin SVM and try to find the hyperplane that makes the least margin violations.\n",
    "\n",
    "For more information on SVM for Scikit-Learn: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing and using SVM\n",
    "StartTimeSVM = time.time()\n",
    "\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(xvectors, newlabels)\n",
    "\n",
    "endTimeSVM = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "We use SVM using Sci-kit Learn.\n",
    "\n",
    "The \"SVC\" is what loads the SVC (Support Vector Classifier) function for SVM. When we call \"clf.fit\", we are fitting our training data and labels for classification. The \"gamma='auto'\" is for choosing the penalty parameter for the regularizer in the SVM optimization formula. Once everything is ran and computed, we record the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time for SVM: 386.64436316490173 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = endTimeSVM - StartTimeSVM\n",
    "print('Computation Time for SVM: ' + str(total_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation with K=5\n",
    "StartTimeSVMCV = time.time()\n",
    "\n",
    "scores = cross_val_score(clf, xvectors, newlabels, cv=5)\n",
    "\n",
    "EndTimeSVMCV = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time for 5-Fold Cross Validation: 1488.1157908439636\n",
      "Total Computation Time for SVM and 5-CV: 1874.7601540088654\n"
     ]
    }
   ],
   "source": [
    "elapsed_time = EndTimeSVMCV - StartTimeSVMCV\n",
    "print('Computation Time for 5-Fold Cross Validation: ' + str(elapsed_time))\n",
    "print('Total Computation Time for SVM and 5-CV: ' + str(total_time + elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores from 5-Fold Cross Validation: [0.81430505 0.81407942 0.81701264 0.816787   0.81159747]\n",
      "Average Score on the Cross Validation: 0.8147563176895307\n"
     ]
    }
   ],
   "source": [
    "print('Scores from 5-Fold Cross Validation: ' + str(scores))\n",
    "print('Average Score on the Cross Validation: ' + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Just looking at the accuracy of each cross validation run, it seems our classifier is at least better than a coin flip. All of the cross validation runs seem to be close to each other, indicating that the model did not overfit to a subsection of the dataset or something weird like that.\n",
    " \n",
    "<br>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions to new dataset\n",
    "predictions = clf.predict(xvectorstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Errors: 3778\n",
      "Accuracy Rate from Test Dataset: 0.8145402778459575\n",
      "\n",
      "Recall: 0.5379413974455297\n",
      "Precision: 0.6848397895743663\n",
      "F-Score: 0.6025667999158426\n"
     ]
    }
   ],
   "source": [
    "# comparing errors\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(newlabelsTest)):\n",
    "    if predictions[i] == newlabelsTest[i]:\n",
    "        if predictions[i] == 1:\n",
    "            TP +=1\n",
    "        else:\n",
    "            TN += 1\n",
    "    else:\n",
    "        if predictions[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "        \n",
    "# printing the total number or errors\n",
    "print('Total Number of Errors: ' + str(numerrors))\n",
    "print('Accuracy Rate from Test Dataset: ' + str(1-numerrors/len(newlabelsTest)) + '\\n')\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "print('Recall: ' + str(recall))\n",
    "print('Precision: ' + str(precision))\n",
    "print('F-Score: ' + str(2/((1/recall)+(1/precision))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks:}$\n",
    "\n",
    "Our recall, precision, and F1-Score indicate that our model is better than a coin flip. From our test set, our accuracy was $81.45\\%.$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Linear Discriminant Analysis (LDA)\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author:}$ Brian Cheng\n",
    "\n",
    "<br>\n",
    "\n",
    "For the second binary classification task, we will implement LDA with Scikit-Learn.\n",
    "\n",
    "As we know, LDA tries to find a hyperplane with a closed-form solution. LDA assumes all the conditional probabilities are Gaussian, and that the variance between classes is the same.\n",
    "\n",
    "For more information on LDA for Scikit-Learn: https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the LDA\n",
    "LDAstartTime = time.time()\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(xvectors, newlabels)\n",
    "\n",
    "LDAendTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Computation Time: 5.15930700302124 seconds\n"
     ]
    }
   ],
   "source": [
    "LDA_time = LDAendTime - LDAstartTime\n",
    "print(\"LDA Computation Time: \" + str(LDA_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing cross validation\n",
    "StartTimeLDACV = time.time()\n",
    "\n",
    "scores = cross_val_score(clf, xvectors, newlabels, cv=5)\n",
    "\n",
    "EndTimeLDACV = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "For LDA, we recorded the time it took to train and the time it took to complete the 5-fold cross validation. The code to run LDA was similar to that of SVM (explained earlier), where \"clf.fit\" calls the training data and labels to be used to compute the parameters of our hyperplane. We then performed 5-fold CV using Scikit-Learn.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA 5-Fold Cross Validation: 20.305153131484985 seconds\n",
      "LDA Total Time for Training and CV: 25.464460134506226 seconds\n",
      "\n",
      "LDA Cross Validation Scores: [0.80482852 0.80888989 0.81069495 0.81227437 0.80708484]\n",
      "Average Score on Cross Validation for LDA: 0.808754512635379\n"
     ]
    }
   ],
   "source": [
    "LDA_CV_time = EndTimeLDACV - StartTimeLDACV\n",
    "total_LDA_time = LDA_time + LDA_CV_time\n",
    "print(\"LDA 5-Fold Cross Validation: \" + str(LDA_CV_time) + \" seconds\")\n",
    "print(\"LDA Total Time for Training and CV: \" + str(total_LDA_time) + \" seconds\" + '\\n')\n",
    "\n",
    "print('LDA Cross Validation Scores: ' + str(scores))\n",
    "print(\"Average Score on Cross Validation for LDA: \" + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(xvectorstest)\n",
    "numerrors = 0\n",
    "for i in range(len(newlabelsTest)):\n",
    "    if predictions[i] != newlabelsTest[i]:\n",
    "        numerrors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Errors: 3897\n",
      "Accuracy Rate from Test Dataset: 0.8086986402238476\n",
      "\n",
      "Recall: 0.5601051840721262\n",
      "Precision: 0.6572625082653736\n",
      "F-Score: 0.6048068147246729\n"
     ]
    }
   ],
   "source": [
    "# comparing errors\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(newlabelsTest)):\n",
    "    if predictions[i] == newlabelsTest[i]:\n",
    "        if predictions[i] == 1:\n",
    "            TP +=1\n",
    "        else:\n",
    "            TN += 1\n",
    "    else:\n",
    "        if predictions[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "        \n",
    "# printing the total number or errors\n",
    "print('Total Number of Errors: ' + str(numerrors))\n",
    "print('Accuracy Rate from Test Dataset: ' + str(1-numerrors/len(newlabelsTest)) + '\\n')\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "print('Recall: ' + str(recall))\n",
    "print('Precision: ' + str(precision))\n",
    "print('F-Score: ' + str(2/((1/recall)+(1/precision))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Running LDA took a total computation time of approximately 25.46 seconds, which is significantly faster than the time it took to run SVM. The reason that LDA was faster was because LDA has a closed-form solution, whereas the hyperplane parameters for SVM are computed using optimization tools. We can see that our F1-score and accuracy rate was about the same as the results from SVM, but since LDA was much faster, we can conclude that LDA is a more efficient algorithm to use in this case.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Using Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author:}$ Soo Min Kwon\n",
    "\n",
    "<br>\n",
    "\n",
    "For the third binary classification task, we will implement QDA with Scikit-Learn.\n",
    "\n",
    "As we know, QDA tries to find a hyperplane with a closed-form solution. QDA assumes all the conditional probabilities are Gaussian, and that the variance between classes is the $\\textit{different}$.\n",
    "\n",
    "For more information on QDA for Scikit-Learn: https://scikit-learn.org/0.16/modules/generated/sklearn.qda.QDA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up QDA\n",
    "QDAstartTime = time.time()\n",
    "\n",
    "clf = clf = QuadraticDiscriminantAnalysis()\n",
    "clf.fit(xvectors, newlabels)\n",
    "\n",
    "QDAendTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Computation Time: 2.9495460987091064 seconds\n"
     ]
    }
   ],
   "source": [
    "QDA_train_time = QDAendTime - QDAstartTime\n",
    "print(\"QDA Computation Time: \" + str(QDA_train_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing 5 fold CV\n",
    "StartTimeQDACV = time.time()\n",
    "\n",
    "scores = cross_val_score(clf, xvectors, newlabels, cv=5)\n",
    "\n",
    "EndTimeQDACV = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "For QDA, similar to LDA, we recorded the time it took to train and the time it took to complete the 5-fold cross validation. The code to run QDA was similar to that of SVM and LDA (explained earlier), where \"clf.fit\" calls the training data and labels to be used to compute the parameters of our hyperplane. We then performed 5-fold CV using Scikit-Learn. The times to run the training and cross validation are shown in the furthering slides.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA 5-Fold Cross Validation ran in 13.996774911880493 seconds\n",
      "Total Time for QDA with Training and CV: 16.9463210105896 seconds\n",
      "\n",
      "Scores for Cross Validation for QDA: [0.79670578 0.80415162 0.80144404 0.80279783 0.79354693]\n",
      "Average Score for Cross Validation for QDA: 0.7997292418772564\n"
     ]
    }
   ],
   "source": [
    "QDA_CV_times = EndTimeQDACV - StartTimeQDACV\n",
    "total_QDA_time = QDA_train_time + QDA_CV_times\n",
    "accuracy_rate = 1-numerrors/len(newlabelsTest)\n",
    "\n",
    "print('QDA 5-Fold Cross Validation ran in ' + str(QDA_CV_times) + ' seconds')\n",
    "print('Total Time for QDA with Training and CV: ' + str(total_QDA_time) + ' seconds' + '\\n')\n",
    "\n",
    "print('Scores for Cross Validation for QDA: ' + str(scores))\n",
    "print(\"Average Score for Cross Validation for QDA: \" + str(np.mean(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(xvectorstest)\n",
    "numerrors = 0\n",
    "for i in range(len(newlabelsTest)):\n",
    "    if predictions[i] != newlabelsTest[i]:\n",
    "        numerrors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Errors from Testing: 4190\n",
      "Accuracy Rate from Test Dataset for QDA: 0.794315448431594\n",
      "\n",
      "Recall: 0.5879038317054845\n",
      "Precision: 0.610612563402263\n",
      "F-Score: 0.5990430622009569\n"
     ]
    }
   ],
   "source": [
    "# comparing errors\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(newlabelsTest)):\n",
    "    if predictions[i] == newlabelsTest[i]:\n",
    "        if predictions[i] == 1:\n",
    "            TP +=1\n",
    "        else:\n",
    "            TN += 1\n",
    "    else:\n",
    "        if predictions[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "        \n",
    "# printing the total number or errors\n",
    "print('Total Number of Errors from Testing: ' + str(numerrors))\n",
    "print('Accuracy Rate from Test Dataset for QDA: ' + str(1-numerrors/len(newlabelsTest)) + '\\n')\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "print('Recall: ' + str(recall))\n",
    "print('Precision: ' + str(precision))\n",
    "print('F-Score: ' + str(2/((1/recall)+(1/precision))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Running QDA took a total of approximately 16.94 seconds, and of course we can expect QDA to be faster than SVM because it has a closed form solution. Like said previously, SVM takes longer because we have to use optimization tools (like Gradient Descent) to find the parameters for the hyperplane. From the values printed above, we have an F-score that is lower than SVM and LDA, and an accuracy that is lower than SVM and LDA as well. The time to find the parameters for QDA was faster than LDA, but since it was not significant, we can conclude that LDA for this dataset is better than QDA. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Final Remarks:}$\n",
    "\n",
    "In future works, we can try different feature extraction methods to test using the same classification methods that we used in this Jupyter notebook. For all three methods that we implemented, the test accuracy was approximately $80\\%$, but the F1-Score $(~60\\%)$ was only slightly better than a coinflip $(50\\%)$. The following are the total computation times (training + cross validation):\n",
    "\n",
    "Computation Time for SVM: 1874.76 seconds\n",
    "\n",
    "Computation Time for LDA: 25.465 seconds\n",
    "\n",
    "Computation time for QDA: 16.946 seconds\n",
    "\n",
    "\n",
    "Even though QDA was slightly faster than LDA, for production, we should recommend LDA, as it got better accuracy on the test data and a better F1-score. However, if the data were to get even larger, then it is possible that QDA might out-perform LDA, given time constraints and similar results.\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Dataset: Classification\n",
    "\n",
    "<br>\n",
    "This part of the Jupyter Notebook is for the $\\textbf{IMDB Text Dataset}$ for the task of $\\textbf{classification}$.\n",
    "\n",
    "The machine learning objective is binary classification of either positive movie review or negative movie review.\n",
    "\n",
    "Each section of this notebook will have code accompanied by a $\\textit{remark}$ section for reasoning of why and what is done in the codes.\n",
    "\n",
    "<br>\n",
    "\n",
    "Below, we will be loading and reshaping the $\\textbf{IMDB Text Dataset}$ into the format that we need for classification.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Pre-processing and Loading of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Dataset: (50000, 2)\n"
     ]
    }
   ],
   "source": [
    "# printing the data\n",
    "imdb_data = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "print('Dimensions of Dataset: ' + str(imdb_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of IMDB Movie Review:\n",
      "\n",
      "Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.\n",
      "\n",
      "This is an example of a positive movie review.\n"
     ]
    }
   ],
   "source": [
    "print('Example of IMDB Movie Review:' + '\\n')\n",
    "print(imdb_data.iloc[5,0] + '\\n')\n",
    "\n",
    "print('This is an example of a ' + str(imdb_data.iloc[5,1]) + ' movie review.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Above is an example of a movie review with its respective label. Reading the movie review, we can conclude that it is a positive movie review. Below, we will be changing the categorical labels to binary labels, which is 1 for positive and 0 for negative.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = imdb_data.shape[0]\n",
    "\n",
    "labels = np.zeros(num_data)\n",
    "count = 0\n",
    "for data in imdb_data.sentiment:\n",
    "    if data == 'positive':\n",
    "        labels[count] = 1\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Ten Labels of Dataset: [1. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('First Ten Labels of Dataset: ' + str(labels[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Above, we can verify that all the labels were correctly label encoded.\n",
    "\n",
    "For processing, we will use the $\\textit{Bag of Words}$ model. Every distinct word that appears across all of the reviews will be a feature. If there are k distinct words, every sample will have a vector for independent variables that is k dimensional. The value of each predictor will be the number of occurances of that word in a particular review. The CountVectorizer class reads through text data and returns a matrix of independent variables corresponding to the number of occurances of words. This coded below:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer()\n",
    "bagOfWords = countVectorizer.fit_transform(imdb_data.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Distinct Words: 102117\n"
     ]
    }
   ],
   "source": [
    "print('Number of Distinct Words: ' + str(bagOfWords.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSums = bagOfWords.sum(0)\n",
    "wordSums.sort()\n",
    "summedWords = bagOfWords.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most commonly used words and their Number of Occurances: \n",
      "\n",
      "the 667933\n",
      "and 324358\n",
      "of 289406\n",
      "to 268119\n",
      "is 211068\n",
      "br 201954\n",
      "it 190828\n",
      "in 186767\n",
      "this 150994\n",
      "that 143870\n",
      "was 95606\n",
      "as 91751\n",
      "movie 87970\n",
      "for 87470\n",
      "with 87362\n",
      "but 83514\n",
      "film 79705\n",
      "you 69119\n",
      "on 68061\n",
      "not 60732\n"
     ]
    }
   ],
   "source": [
    "print('Most commonly used words and their Number of Occurances: ' + '\\n')\n",
    "for i in range(20):\n",
    "    print(countVectorizer.get_feature_names()[(int)(np.where(summedWords==wordSums[0,102116-i])[1])] + ' ' + str(wordSums[0,102116-i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left, you can observe the most frequently used words across the whole dataset, along with the number of times they appear in the data. Below, we will be splitting the data into training and testing:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 40000\n",
    "test_split = 10000\n",
    "\n",
    "trainingBag = bagOfWords[:train_split]\n",
    "testBag = bagOfWords[train_split:train_split+test_split]\n",
    "trainingLabels = labels[:train_split]\n",
    "testLabels = labels[train_split:train_split+test_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "For $\\textbf{Feature Learning}$:\n",
    "\n",
    "The CountVectorizer stores the features as a sparse matrix because the vast majority of the entries are zeros. That is because there is a feature for every distinct word that appears across all the movie reviews, so words that are unique and only appear in a few of the reviews will have all zero entries across almost all of the 50000 samples. Because the matrix is so sparse, PCA is not an effective dimensionality reduction method. However, we certainly do want to reduce the dimension somehow, because there are certainly some features that are very insignificant for our classification problem. Instead of PCA, we use Truncated SVD to reduce dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using truncated SVD on the sparse matrix\n",
    "truncatedSVD = TruncatedSVD(n_components=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording the time it takes to perform SVD\n",
    "startTime = time.time()\n",
    "reducedFeatures = truncatedSVD.fit_transform(trainingBag)\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time for SVD: 87.48479890823364 seconds\n",
      "\n",
      "Dimensions of Reduced Feature Matrix: (40000, 1000)\n"
     ]
    }
   ],
   "source": [
    "SVD_time = endTime-startTime\n",
    "print('Computation Time for SVD: ' + str(SVD_time) + ' seconds' + '\\n')\n",
    "\n",
    "print('Dimensions of Reduced Feature Matrix: ' + str(reducedFeatures.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also run the same dimensionality reduction transformation that was learned from the training set on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD on testing data\n",
    "reducedFeaturesTest = truncatedSVD.transform(testBag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Using Gaussian Naive Bayes\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author:}$ Manish Kewalramani\n",
    "\n",
    "For the first classification method, we decided to use the Gaussian Naive Bayes algorithm available on Scikit-Learn. Gaussian Naive Bayes assumes that all the conditional probabilities are Gaussian and independent. For example, let's say we had a dataset that was of class male or female, with attributes weight and height. The probability of weight given male would be independent from height given male.\n",
    "\n",
    "For more information on Gaussian Naive Bayes for Scikit-Learn: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up Gaussian Naive Bayes\n",
    "classifier1 = GaussianNB()\n",
    "startTime = time.time()\n",
    "classifier1.fit(reducedFeatures,trainingLabels)\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time to Train Gaussian Naive Bayes: 0.7588191032409668 seconds\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_training = endTime-startTime\n",
    "print('Computation Time to Train Gaussian Naive Bayes: ' + str(naive_bayes_training) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing 5-fold cross validation\n",
    "startTime = time.time()\n",
    "scores = cross_val_score(classifier1,reducedFeatures,trainingLabels,cv=5)\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for Cross Validation: [0.87864017 0.87301587 0.86925    0.87335917 0.87060883]\n",
      "Average Scores for Cross Validation: 0.8729748077988251\n",
      "\n",
      "Computation Time for Cross Validation: 25.113062143325806 seconds\n",
      "Total Computation Time for Gaussian Naive Bayes: 25.871881246566772\n"
     ]
    }
   ],
   "source": [
    "print('Scores for Cross Validation: ' + str(scores))\n",
    "print('Average Scores for Cross Validation: ' + str(np.mean(scores)) + '\\n')\n",
    "\n",
    "CV_naive_time = endTime - startTime\n",
    "print('Computation Time for Cross Validation: ' + str(CV_naive_time) + ' seconds')\n",
    "print('Total Computation Time for Gaussian Naive Bayes: ' + str(CV_naive_time + naive_bayes_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on test\n",
    "predictions = classifier1.predict(reducedFeaturesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerrors = 0\n",
    "for i in range(len(testLabels)):\n",
    "    if predictions[i] != testLabels[i]:\n",
    "        numerrors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Errors from Testing: 4789\n",
      "Accuracy Rate from Test Dataset for Gaussian Naive Bayes: 0.5211\n",
      "\n",
      "Recall: 0.26143399241062515\n",
      "Precision: 0.5454166666666667\n",
      "F-Score: 0.3534494397191846\n"
     ]
    }
   ],
   "source": [
    "# comparing errors\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(testLabels)):\n",
    "    if predictions[i] == testLabels[i]:\n",
    "        if predictions[i] == 1:\n",
    "            TP +=1\n",
    "        else:\n",
    "            TN += 1\n",
    "    else:\n",
    "        if predictions[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "        \n",
    "# printing the total number or errors\n",
    "print('Total Number of Errors from Testing: ' + str(numerrors))\n",
    "print('Accuracy Rate from Test Dataset for Gaussian Naive Bayes: ' + str(1-numerrors/len(testLabels)) + '\\n')\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "print('Recall: ' + str(recall))\n",
    "print('Precision: ' + str(precision))\n",
    "print('F-Score: ' + str(2/((1/recall)+(1/precision))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "We can conclude that Gaussian Naive Bayes algorithm for this dataset is a very poor choice, as the F1-score is lower than 0.5 (worse than a coin flip). We can also observe that the accuracy rate from our test dataset was 0.5211, which is basically making random classification decisions.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Classification Using Linear Discriminant Analysis (LDA)\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author:}$ Soo Min Kwon\n",
    "\n",
    "Linear Discriminant Analysis, or LDA, has a closed-form solution and assumes that the conditional probability of our data is Gaussian with same mean and $\\textit{same}$ variance.\n",
    "\n",
    "For more information about LDA, refer to the link given in the Audio dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training LDA classifier\n",
    "classifier2 = LDA()\n",
    "startTime = time.time()\n",
    "classifier2.fit(reducedFeatures,trainingLabels)\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time for LDA Training: 6.454540967941284 seconds\n"
     ]
    }
   ],
   "source": [
    "# printing computation times for training for LDA\n",
    "\n",
    "LDA_train_time = endTime - startTime\n",
    "print('Computation Time for LDA Training: ' + str(LDA_train_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing 5-fold CV\n",
    "startTime = time.time()\n",
    "scores = cross_val_score(classifier2,reducedFeatures,trainingLabels,cv=5)\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time for Cross Validation: 25.113062143325806 seconds\n",
      "Total Computation Time for LDA: 31.56760311126709 seconds\n",
      "\n",
      "Scores for 5-Fold Cross Validation: [0.87864017 0.87301587 0.86925    0.87335917 0.87060883]\n",
      "Average Scores for 5-Fold Cross Validation: 0.8729748077988251\n"
     ]
    }
   ],
   "source": [
    "LDA_CV_time = endTime-startTime\n",
    "\n",
    "print('Computation Time for Cross Validation: ' + str(LDA_CV_time) + ' seconds')\n",
    "print('Total Computation Time for LDA: ' + str(LDA_train_time + LDA_CV_time) + ' seconds' + '\\n')\n",
    "\n",
    "print('Scores for 5-Fold Cross Validation: ' + str(scores))\n",
    "print('Average Scores for 5-Fold Cross Validation: ' + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions\n",
    "predictions = classifier2.predict(reducedFeaturesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerrors = 0\n",
    "for i in range(len(testLabels)):\n",
    "    if predictions[i] != testLabels[i]:\n",
    "        numerrors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Errors from Testing: 1260\n",
      "Accuracy Rate from Test Dataset for LDA: 0.874\n",
      "\n",
      "Recall: 0.8875574196125424\n",
      "Precision: 0.8644232639564287\n",
      "F-Score: 0.8758376034686637\n"
     ]
    }
   ],
   "source": [
    "# comparing errors\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(testLabels)):\n",
    "    if predictions[i] == testLabels[i]:\n",
    "        if predictions[i] == 1:\n",
    "            TP +=1\n",
    "        else:\n",
    "            TN += 1\n",
    "    else:\n",
    "        if predictions[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "        \n",
    "# printing the total number or errors\n",
    "print('Total Number of Errors from Testing: ' + str(numerrors))\n",
    "print('Accuracy Rate from Test Dataset for LDA: ' + str(1-numerrors/len(testLabels)) + '\\n')\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "print('Recall: ' + str(recall))\n",
    "print('Precision: ' + str(precision))\n",
    "print('F-Score: ' + str(2/((1/recall)+(1/precision))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Above, we can observe the accuracy on the test dataset, which was approximately $87\\%$, much higher than that of the accuracy rate of Gaussian Naive Bayes. This is to be expected because having indepdent conditional probabilities (assumption in Gaussian Naive Bayes) is a pretty 'naive' assumption. We can also see that the recall, precision, and F1-score for LDA was also high, much better than the results from the previous algorithm.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Classification Using Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Author: }$ Brian Cheng\n",
    "\n",
    "<br>\n",
    "\n",
    "Quadratic Discriminant Analysis, or QDA, has a closed-form solution and assumes that the conditional probability of our data is Gaussian with same mean and $\\textit{different}$ variance.\n",
    "\n",
    "For more information about QDA, refer to the link given in the Audio dataset.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using QDA\n",
    "classifier3 = QDA()\n",
    "startTime = time.time()\n",
    "classifier3.fit(reducedFeatures,trainingLabels)\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time to Train QDA: 5.077404975891113 seconds\n"
     ]
    }
   ],
   "source": [
    "QDA_train_time = endTime-startTime\n",
    "print('Computation Time to Train QDA: ' + str(QDA_train_time) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing CV\n",
    "startTime = time.time()\n",
    "scores = cross_val_score(classifier3,reducedFeatures,trainingLabels,cv=5)\n",
    "endTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Time for Cross Validation: 21.121999740600586 seconds\n",
      "Total Computation Time for QDA: 26.1994047164917 seconds\n",
      "\n",
      "Scores for 5-Fold Cross Validation: [0.69616298 0.68591426 0.699      0.69771221 0.69008626]\n",
      "Average Scores for 5-Fold Cross Validation: 0.6937751430308616\n"
     ]
    }
   ],
   "source": [
    "QDA_CV_time = endTime-startTime\n",
    "\n",
    "print('Computation Time for Cross Validation: ' + str(QDA_CV_time) + ' seconds')\n",
    "print('Total Computation Time for QDA: ' + str(QDA_train_time + QDA_CV_time) + ' seconds' + '\\n')\n",
    "\n",
    "print('Scores for 5-Fold Cross Validation: ' + str(scores))\n",
    "print('Average Scores for 5-Fold Cross Validation: ' + str(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making predictions on testing\n",
    "predictions = classifier3.predict(reducedFeaturesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerrors = 0\n",
    "for i in range(len(testLabels)):\n",
    "    if predictions[i] != testLabels[i]:\n",
    "        numerrors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Errors from Testing: 3193\n",
      "Accuracy Rate from Test Dataset for LDA: 0.6807000000000001\n",
      "\n",
      "Recall: 0.45336528859596564\n",
      "Precision: 0.8327219369038885\n",
      "F-Score: 0.5870942713047976\n"
     ]
    }
   ],
   "source": [
    "# comparing errors\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in range(len(testLabels)):\n",
    "    if predictions[i] == testLabels[i]:\n",
    "        if predictions[i] == 1:\n",
    "            TP +=1\n",
    "        else:\n",
    "            TN += 1\n",
    "    else:\n",
    "        if predictions[i] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "        \n",
    "# printing the total number or errors\n",
    "print('Total Number of Errors from Testing: ' + str(numerrors))\n",
    "print('Accuracy Rate from Test Dataset for LDA: ' + str(1-numerrors/len(testLabels)) + '\\n')\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "print('Recall: ' + str(recall))\n",
    "print('Precision: ' + str(precision))\n",
    "print('F-Score: ' + str(2/((1/recall)+(1/precision))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textit{Remarks: }$\n",
    "\n",
    "Above, we can observe the accuracy on the test dataset, which was approximately $68\\%$, much higher than that of the accuracy rate of Gaussian Naive Bayes, but lower than that of LDA. We can also see that the recall, precision, and F1-score for LDA was higher than the Gaussian Naive Bayes values, but lower than QDA. Since the computation time was about the same as the others, we can conclude that LDA is more efficient than QDA in this case.\n",
    "\n",
    "<br>\n",
    "\n",
    "$\\textbf{Final Remarks:}$\n",
    "\n",
    "For future works, we can try different feature extraction methods to test using the same classification methods that we used in this Jupyter notebook. For all three methods that we implemented, the test accuracy significantly varied throughout the algorithms we used. Likewise, the precision, recall, and F1-scores varied as well. Below, we can observe the computation times:\n",
    "\n",
    "Computation Time for Gaussian Naive Bayes: 25.87 seconds\n",
    "\n",
    "Computation Time for LDA: 31.56 seconds\n",
    "\n",
    "Computation time for QDA: 26.19 seconds\n",
    "\n",
    "\n",
    "Overall, for production, we can conclude that LDA would be the best algorithm to use, as it achieves much higher accuracy and F1-scores, and does not have a significant change in computation times as the other algorithms we used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
